---
layout: post
title: Associative Embedding 论文笔记
date: 2018-12-09
categories: [论文笔记]
tags: 论文笔记
---
<!--more-->

### 大致想法
有很多的任务的模式是先检测后分组，比如多人姿态估计，实例分割，多目标追踪。之前在这类任务上大部分是多个stage的想法来做的，即先做检测再做分组，但是这个Paper里提出的方法是检测和分组可以同时做，其想法是在检测的同时附加上一个embedding用来打tag,然后利用这些tag去分组，这样就一步到位了，而且作者在paper里提到，其实分多个stage的办法并没有充分利用到一个feature上的语义信息，而同时做检测和分组，就可以做到这一点。
网络会输出检测的heatmap，也会同时输出一个embeddings,这样输出的channels数目会加倍，最终的结果都是通过取heatmap上的最高的响应值来做的。
但是有一点需要注意，tags并没有gt,因为tags的值是多少并不重要，重要的是属于同一个人的关节点对应的tag相接近，不是同一个人的关节点对应的tag要远离，所以作者在后面设计的这一部分的loss是`push`+`pull`二者合起来的一个loss,即同一个人的`pull`，不是同一个人的`push`.
如下所示

![avator](/images/embedding1.png)
上面的第一项就是属于同一个人的要`pull`，其中的平均值是一个人的所有关节点的位置的平均，第二项就是`pull`，就是不同的人的关键点的平均之间要相互远离。

在多人姿态估计的任务中，大致有两种方法，即top-down和bottom-up，前者是先检测人后检测每个人的kpts,后者是先检测所有人的关键点，然后再分组。多人姿态估计比单人的要难得多，因为要检测出一张图上的所有的人，对于人的位置信息先验的是不知道的，而且人与人之间会有行重叠。这个paper中的方法和bottom-up方法有些相似，但是并不一样，因为这里的方法可以同时检测完了之后就会知道他们对应的组了。

主体网络采用的是stacked hourglass.网络不断地重复着bottom-up, top-down的推理来产生一系列的中间的predictions,直到最后产生一个最终的结果，这些过程可以理解成是refine的一个过程。在其它的网络结构中也有这种类似的想法。
![avator](/images/embedding2.png)

其中蓝色的就是中间的结果，绿色的就是最终的结果。中间的每个小方框都是一个3-3的卷积，在不同的scales之间用了很多的upsampling和相加的操作。
现在感觉这个paper的主要想法是用一种方式很好的将多人姿态估计转化成为了单人的姿态估计,感觉上像是把整个图上的所有的人看成一个“大人”，而其中每个人的关节点的集合，相当于是这个”大人“的某一个关节.所以可以用单人姿态估计时的网络架构。
最终每个检测的结果实际上都是由它的”score“和"embedding tag"来定义的，而每个人是由他当前的关节点的平均定义的。最后分组的过程有些像聚类。方法是先获得躯干编码再获取四肢编码（估计这要对做gt的时候有一定的顺序要求），对于新检测到的肢体，分别与现有的个体（每次检测同一个肢体的时候，相同肢体的个数就代表了个体数）计算距离，如果距离小的话，就认为是属于同一个人的，这个过程感觉就像是k-means里的过程，如果某一个新的肢体与之前的离的都比较远，就认为是一个新的人的肢体。然后一直这样下去。

### 思考 

感觉有许多的地方是需要研究的，这里面的黑盒子目前有些多。感觉这种bottom-up的方法的关键在于如何把得到的关节点给聚类，检测到关节点可能不是太难，所以重要的是如何想到一个好的聚类的办法。



