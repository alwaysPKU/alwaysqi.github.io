---
layout: post
title: fcn论文笔记
date: 2018-12-26
categories: [论文笔记]
tags: 论文笔记
---
<!--more-->

fcn之前读过一次，现在在想想其中的一些值得回味的东西,图像分割任务是将一幅图中各个实体的边界确定下来，这样就可以通过寻找这个实体的边界来确定实体的位置，感觉会在自动驾驶任务中用的非常多。而目前的做法是采用分类的办法来做的，即对图像的每个像素点都进行分类，分类完成后，最后把相邻并且属于同一类别的像素点聚集起来。

### fcn的方案：

fcn不包含全连接层，但是它为什么要设计成这样呢？

先recall一下fc层的用处，比如在Alexnet做cifar10的分类的时候，每个图片经过提取特征转化成为了一个长为4096的向量，然后就进入了fc层去做了分类，那时候一张图上只有一个物体，而现在一张图上可能有多个物体，如果再用fc层的话，也需要把得到的特征flatten一个一维的，然后才能进入fc层，但是这样就失去了其位置的信息，而全部采用cnn就可以避免出现上面的问题，也就是说使用全cnn是一种目前想到的解决方式。

### 新的问题：

既然要对每个像素都进行分类，那么输出的shape和输入的shape一定是一样的，不然就不会是每个像素点的分类了，那这样一个自然的想法是，在每经过一个层的时候都不要改变其shape就行了，这样输出就和输入的shape肯定是一样的了，但是这样新的问题出现了。因为都用同一个shape的话，计算量明显增加了，特别是对于输入比较大的情况，这是不符合'小，轻，快，准'的要求的.

进一步想，能不能先将信息提出出来再"还原"出来，这就是现在经常看到的一种encode-decode的结构，而且还可以利用不同scale的feature,fcn也是这种架构，里面进行了卷积和反卷积的操作，卷积是变小的操作，反卷积是变大的操作，关于变大的操作有的是直接用的'upsampling'，但是这样太暴力了，所以往往会在'upsampling'之前和之后都接一个小的卷积层，让其先适应一下。fcn中用的反卷积操作也是为了防止太暴力而提出的解决方案，不过需要注意的是，其实任何形式的这种由小维度变成大维度的时候，都会有一些精度损失，为了提高精度，采用的办法是融合，即融合不同scale的特征。


### 评测

虽然是对每个像素都做了分类，但是计算Loss的时候好像并不是用的所有的像素点，感觉这样是对的，因为如果所有的像素点都用到的话，首先是计算量大，其次的原因是相邻的像素点的信息可能大多数都一样（只有两个物体的边界的那些部分不太一样），比如一张图上如果有一只老虎和一只蚂蚁的话，那如果所有的像素点全部采用的话，loss将会由属于老虎的那些像素点来提供，那么就会偏重于老虎这一部分。

评测的办法用的是IOU， 这个感觉也挺自然的，一方面预测的有一片区域A，而gt也有一部分区域B，所以自然地想到的是IOU，注意IOU只是一个让人来看的指标，并不是Loss，这种想法也可以用到其他的任务上面，比如缺陷检测。





