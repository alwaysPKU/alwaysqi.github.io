<DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>pytorch-cuda和c++的extensions</title>
  <meta name="description" content="">
  <meta name="author" content="leopardpan">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="pytorch-cuda和c++的extensions">
  <meta name="twitter:description" content="">
  <meta property="og:type" content="article">
  <meta property="og:title" content="pytorch-cuda和c++的extensions">
  <meta property="og:description" content="">
  
  <link rel="icon" type="image/png" href="/images/favicon.png" />
  <link href="/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="canonical" href="http://localhost:4000/2018/12/roc-torch2/">
  <link rel="alternate" type="application/rss+xml" title="倔强的生命！" href="http://localhost:4000/feed.xml">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />

<!-- 站点统计 -->
  <script 
  async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>  

<!-- 百度统计 -->
  

<!-- google 统计 -->
  

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-9005224472374751",
    enable_page_level_ads: true
  });
</script>

</head>


  <body>

    <span class="mobile btn-mobile-menu">        
      <div class="nav_container">
         <nav class="nav-menu-item" style = "float:right">
            <i class="nav-menu-item">
              <a href="/#blog" title="" class="blog-button">  博客主页
              </a>
            </i>
            
                <i class="nav-menu-item">

                  <a href="/archive" title="archive" class="btn-mobile-menu__icon">
                      所有文章
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/tags" title="tags" class="btn-mobile-menu__icon">
                      标签
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/about" title="about" class="btn-mobile-menu__icon">
                      关于我
                  </a>
                </i>
            
          </nav>
      </div>
    </span>
    
    <header class="panel-cover panel-cover--collapsed" style="background-image: url('/images/background-cover.jpg')">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">
        <!-- 头像效果-start -->
        <div class="ih-item circle effect right_to_left">            
            <a href="/#blog" title="前往 倔强的生命！ 的主页" class="blog-button">
                <div class="img"><img src="/images/avatar.jpg" alt="img"></div>
                <div class="info">
                    <div class="info-back">
                        <h2> 
                            
                                BEYOND
                            
                        </h2>
                        <p>
                           
                                Come on!
                            
                        </p>
                    </div>
                </div>
            </a>
        </div>
        <!-- 头像效果-end -->
        <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for 倔强的生命！" class="blog-button">倔强的生命！</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">何不如此！</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">欢迎~</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        
        

        <div class="navigation-wrapper">
          <div>
            <nav class="cover-navigation cover-navigation--primary">
              <ul class="navigation">
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">博客主页</a></li>
                
                  <li class="navigation__item"><a href="/archive" title="archive">所有文章</a></li>
                
                  <li class="navigation__item"><a href="/tags" title="tags">标签</a></li>
                
                  <li class="navigation__item"><a href="/about" title="about">关于我</a></li>
                
              </ul>
            </nav>
          </div>          
        </div>


        </div>
      </div>
    </div>
    
    
    <div class="panel-cover--overlay cover-clear"></div>
    
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title">pytorch-cuda和c++的extensions</h1>
    <div class="post-meta">
      <img src="/images/calendar.png" width="20px"/> 
      <time datetime="2018-12-23 00:00:00 +0800" itemprop="datePublished" class="post-meta__date date">2018-12-23</time>  
         
      <!--<span id="busuanzi_container_page_pv"> | 阅读:<span id="busuanzi_value_page_pv"></span>次</span> -->
    </p>
    </div>
  </header>

  <section class="post">
    <!--more-->

<p>这次是基于最新的pytorch 1.0.0 版本的来看的。</p>

<p>先以官方的教程为例子来试一下。</p>

<h3 id="c-extension">c++ extension</h3>

<ul>
  <li>第一步写<code class="highlighter-rouge">.cpp</code>文件</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#include &lt;torch/torch.h&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;

at::Tensor d_sigmoid(at::Tensor z) {
  auto s = at::sigmoid(z);
  return (1 - s) * s;
}


std::vector&lt;at::Tensor&gt; lltm_forward(
    at::Tensor input,
    at::Tensor weights,
    at::Tensor bias,
    at::Tensor old_h,
    at::Tensor old_cell) {
  auto X = at::cat({old_h, input}, /*dim=*/1);

  auto gate_weights = at::addmm(bias, X, weights.transpose(0, 1));
  auto gates = gate_weights.chunk(3, /*dim=*/1);

  auto input_gate = at::sigmoid(gates[0]);
  auto output_gate = at::sigmoid(gates[1]);
  auto candidate_cell = at::elu(gates[2], /*alpha=*/1.0);

  auto new_cell = old_cell + candidate_cell * input_gate;
  auto new_h = at::tanh(new_cell) * output_gate;

  return {new_h,
          new_cell,
          input_gate,
          output_gate,
          candidate_cell,
          X,
          gate_weights};
}

at::Tensor d_tanh(at::Tensor z) {
  return 1 - z.tanh().pow(2);
}

// elu'(z) = relu'(z) + { alpha * exp(z) if (alpha * (exp(z) - 1)) &lt; 0, else 0}
at::Tensor d_elu(at::Tensor z, at::Scalar alpha = 1.0) {
  auto e = z.exp();
  auto mask = (alpha * (e - 1)) &lt; 0;
  return (z &gt; 0).type_as(z) + mask.type_as(z) * (alpha * e);
}

std::vector&lt;at::Tensor&gt; lltm_backward(
    at::Tensor grad_h,
    at::Tensor grad_cell,
    at::Tensor new_cell,
    at::Tensor input_gate,
    at::Tensor output_gate,
    at::Tensor candidate_cell,
    at::Tensor X,
    at::Tensor gate_weights,
    at::Tensor weights) {
  auto d_output_gate = at::tanh(new_cell) * grad_h;
  auto d_tanh_new_cell = output_gate * grad_h;
  auto d_new_cell = d_tanh(new_cell) * d_tanh_new_cell + grad_cell;

  auto d_old_cell = d_new_cell;
  auto d_candidate_cell = input_gate * d_new_cell;
  auto d_input_gate = candidate_cell * d_new_cell;


auto gates = gate_weights.chunk(3, /*dim=*/1);
  d_input_gate *= d_sigmoid(gates[0]);
  d_output_gate *= d_sigmoid(gates[1]);
  d_candidate_cell *= d_elu(gates[2]);

  auto d_gates =
     at::cat({d_input_gate, d_output_gate, d_candidate_cell}, /*dim=*/1);

  auto d_weights = d_gates.t().mm(X);
  auto d_bias = d_gates.sum(/*dim=*/0, /*keepdim=*/true);

  auto d_X = d_gates.mm(weights);
  const auto state_size = grad_h.size(1);
  auto d_old_h = d_X.slice(/*dim=*/1, 0, state_size);
  auto d_input = d_X.slice(/*dim=*/1, state_size);

  return {d_old_h, d_input, d_weights, d_bias, d_old_cell};
}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
  m.def("forward", &amp;lltm_forward, "LLTM forward");
  m.def("backward", &amp;lltm_backward, "LLTM backward");
}

</code></pre></div></div>

<p>注意最后的<code class="highlighter-rouge">PYBIND11</code>那些不要忘记了，其作用是告诉在外边该怎么调这个接口，比如最后<code class="highlighter-rouge">lltm.forward</code> 通过这里的指向，就会调用<code class="highlighter-rouge">lltm_forward</code>这个函数，后面加引号的是对其的描述。</p>

<ul>
  <li>第二步写setup.py</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from setuptools import setup
from torch.utils.cpp_extension import CppExtension, BuildExtension
import setuptools
import torch
setup(name='lltm',
      ext_modules=[CppExtension('lltm', ['lltm.cpp'])],
     cmdclass={'build_ext': BuildExtension})


"""
setuptools.Extension(
   name='lltm',
   sources=['lltm.cpp'],
   include_dirs=torch.utils.cpp_extension.include_paths(),
   language='c++')
"""


</code></pre></div></div>

<p><code class="highlighter-rouge">setup.py</code>有两种方式可以用，上面的一种是会生成一些东西，而下面的不会，先以上面的为例，写好之后</p>

<p>运行<code class="highlighter-rouge">python setup.py install</code>
这时候结果如下</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>running install
running bdist_egg
running egg_info
writing lltm.egg-info/PKG-INFO
writing dependency_links to lltm.egg-info/dependency_links.txt
writing top-level names to lltm.egg-info/top_level.txt
reading manifest file 'lltm.egg-info/SOURCES.txt'
writing manifest file 'lltm.egg-info/SOURCES.txt'
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_ext
building 'lltm' extension
gcc -pthread -B /home/pengkun/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/pengkun/anaconda3/lib/python3.6/site-packages/torch/lib/include -I/home/pengkun/anaconda3/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/home/pengkun/anaconda3/lib/python3.6/site-packages/torch/lib/include/TH -I/home/pengkun/anaconda3/lib/python3.6/site-packages/torch/lib/include/THC -I/home/pengkun/anaconda3/include/python3.6m -c lltm.cpp -o build/temp.linux-x86_64-3.6/lltm.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=lltm -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11
cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
In file included from lltm.cpp:1:0:
/home/pengkun/anaconda3/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2: warning: #warning "Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h" [-Wcpp]
 #warning \
  ^
g++ -pthread -shared -B /home/pengkun/anaconda3/compiler_compat -L/home/pengkun/anaconda3/lib -Wl,-rpath=/home/pengkun/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/lltm.o -o build/lib.linux-x86_64-3.6/lltm.cpython-36m-x86_64-linux-gnu.so
creating build/bdist.linux-x86_64/egg
copying build/lib.linux-x86_64-3.6/lltm.cpython-36m-x86_64-linux-gnu.so -&gt; build/bdist.linux-x86_64/egg
creating stub loader for lltm.cpython-36m-x86_64-linux-gnu.so
byte-compiling build/bdist.linux-x86_64/egg/lltm.py to lltm.cpython-36.pyc
creating build/bdist.linux-x86_64/egg/EGG-INFO
copying lltm.egg-info/PKG-INFO -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
copying lltm.egg-info/SOURCES.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
copying lltm.egg-info/dependency_links.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
copying lltm.egg-info/top_level.txt -&gt; build/bdist.linux-x86_64/egg/EGG-INFO
writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt
zip_safe flag not set; analyzing archive contents...
__pycache__.lltm.cpython-36: module references __file__
creating 'dist/lltm-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing lltm-0.0.0-py3.6-linux-x86_64.egg
removing '/home/pengkun/anaconda3/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg' (and everything under it)
creating /home/pengkun/anaconda3/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg
Extracting lltm-0.0.0-py3.6-linux-x86_64.egg to /home/pengkun/anaconda3/lib/python3.6/site-packages
lltm 0.0.0 is already the active version in easy-install.pth

Installed /home/pengkun/anaconda3/lib/python3.6/site-packages/lltm-0.0.0-py3.6-linux-x86_64.egg
Processing dependencies for lltm==0.0.0
Finished processing dependencies for lltm==0.0.0

</code></pre></div></div>
<p>没编译之前文件目录结构是</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── lltm.cpp
└── setup.py

</code></pre></div></div>

<p>编译完成后是</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── build
│   ├── bdist.linux-x86_64
│   ├── lib.linux-x86_64-3.6
│   │   └── lltm.cpython-36m-x86_64-linux-gnu.so
│   └── temp.linux-x86_64-3.6
│       └── lltm.o
├── dist
│   └── lltm-0.0.0-py3.6-linux-x86_64.egg
├── lltm.cpp
├── lltm.egg-info
│   ├── dependency_links.txt
│   ├── PKG-INFO
│   ├── SOURCES.txt
│   └── top_level.txt
└── setup.py


</code></pre></div></div>
<p>这时候可以测试一下</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; import lltm
&gt;&gt;&gt; lltm.forward
&lt;built-in method forward of PyCapsule object at 0x7f8c2bc5ef00&gt;
&gt;&gt;&gt; 

</code></pre></div></div>

<p>注意一定是<code class="highlighter-rouge">import torch</code>在前面！！！</p>

<p>用的时候可以这样使用</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch
import lltm
outputs = lltm.forward(input, weights, bias, old_h, old_cell)

</code></pre></div></div>

<ul>
  <li>用第二种方法编译</li>
</ul>

<p>第二种方法没有生成东西</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pengkun@ubuntu:~/torch_learn/lltm_extension$ vim setup.py 
pengkun@ubuntu:~/torch_learn/lltm_extension$ python setup.py install
pengkun@ubuntu:~/torch_learn/lltm_extension$ ls
lltm.cpp  setup.py
pengkun@ubuntu:~/torch_learn/lltm_extension$ 
</code></pre></div></div>
<p>建议用第一种，因为第二种教程里面没有怎么说。</p>

<h3 id="还可以更方便地采取jit的方式just-in-time的方式">还可以更方便地采取jit的方式（Just in time）的方式</h3>

<p>这时候不需要像之前那样<code class="highlighter-rouge">python setup.py install</code>
直接用的时候像下面这样用就可以了，不过第一次用的时候会慢，</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; from torch.utils.cpp_extension import load
&gt;&gt;&gt; 
&gt;&gt;&gt; lltm = load(name="lltm", sources=["lltm.cpp"])
&gt;&gt;&gt; lltm.forward
&lt;built-in method forward of PyCapsule object at 0x7f524d32e750&gt;
&gt;&gt;&gt; 

</code></pre></div></div>
<p><code class="highlighter-rouge">lltm.forward</code> 后面跟上输出的数据就可以用了</p>

<h3 id="cuda-extensions">cuda extensions</h3>

<ul>
  <li>写核函数
这里把主要部分拿出来，核函数的细节省略了，官方的教程上面是有的，</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// lltm_cuda_kernel.cu 
#include &lt;ATen/ATen.h&gt;
#include &lt;cuda.h&gt;
#include &lt;cuda_runtime.h&gt;
#include &lt;vector&gt;

/*

kernel funciton

*/

std::vector&lt;at::Tensor&gt; lltm_cuda_forward(
    at::Tensor input,
    at::Tensor weights,
    at::Tensor bias,
    at::Tensor old_h,
    at::Tensor old_cell)
{ 
  auto X = at::cat({old_h, input}, /*dim=*/1);
  auto gates = at::addmm(bias, X, weights.transpose(0, 1));
  
  const auto batch_size = old_cell.size(0);
  const auto state_size = old_cell.size(1);
  
  auto new_h = at::zeros_like(old_cell);
  auto new_cell = at::zeros_like(old_cell);
  auto input_gate = at::zeros_like(old_cell);
  auto output_gate = at::zeros_like(old_cell);
  auto candidate_cell = at::zeros_like(old_cell);
  
  const int threads = 1024;
  const dim3 blocks((state_size + threads - 1) / threads, batch_size);
  
  AT_DISPATCH_FLOATING_TYPES(gates.type(), "lltm_forward_cuda", ([&amp;] {
    lltm_cuda_forward_kernel&lt;scalar_t&gt;&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(
        gates.data&lt;scalar_t&gt;(),
        old_cell.data&lt;scalar_t&gt;(),
        new_h.data&lt;scalar_t&gt;(),
        new_cell.data&lt;scalar_t&gt;(),
        input_gate.data&lt;scalar_t&gt;(),
        output_gate.data&lt;scalar_t&gt;(),
        candidate_cell.data&lt;scalar_t&gt;(),
        state_size);
  }));



/*

kernel function

*/

std::vector&lt;at::Tensor&gt; lltm_cuda_backward(
    at::Tensor grad_h,
    at::Tensor grad_cell,
    at::Tensor new_cell,
    at::Tensor input_gate,
    at::Tensor output_gate,
    at::Tensor candidate_cell,
    at::Tensor X,
    at::Tensor gate_weights,
    at::Tensor weights)
{

  auto d_old_cell = at::zeros_like(new_cell);
  auto d_gates = at::zeros_like(gate_weights);

  const auto batch_size = new_cell.size(0);
  const auto state_size = new_cell.size(1);

  const int threads = 1024;
  const dim3 blocks((state_size + threads - 1) / threads, batch_size);

  AT_DISPATCH_FLOATING_TYPES(X.type(), "lltm_forward_cuda", ([&amp;] {
    lltm_cuda_backward_kernel&lt;scalar_t&gt;&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(
        d_old_cell.data&lt;scalar_t&gt;(),
        d_gates.data&lt;scalar_t&gt;(),
        grad_h.contiguous().data&lt;scalar_t&gt;(),
        grad_cell.contiguous().data&lt;scalar_t&gt;(),
        new_cell.contiguous().data&lt;scalar_t&gt;(),
        input_gate.contiguous().data&lt;scalar_t&gt;(),
        output_gate.contiguous().data&lt;scalar_t&gt;(),
        candidate_cell.contiguous().data&lt;scalar_t&gt;(),
        gate_weights.contiguous().data&lt;scalar_t&gt;(),
        state_size);
  }));

  auto d_weights = d_gates.t().mm(X);
  auto d_bias = d_gates.sum(/*dim=*/0, /*keepdim=*/true);

  auto d_X = d_gates.mm(weights);
  auto d_old_h = d_X.slice(/*dim=*/1, 0, state_size);
  auto d_input = d_X.slice(/*dim=*/1, state_size);

  return {d_old_h, d_input, d_weights, d_bias, d_old_cell, d_gates};
}

</code></pre></div></div>

<p>注意这里不像上一个blog写的那样进行编译cuda核函数。</p>

<ul>
  <li>写一个”.cpp”的连接文件</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#include &lt;torch/torch.h&gt;
#include &lt;vector&gt;
// CUDA forward declarations
std::vector&lt;at::Tensor&gt; lltm_cuda_forward(
    at::Tensor input,
    at::Tensor weights,
    at::Tensor bias,
    at::Tensor old_h,
    at::Tensor old_cell);
std::vector&lt;at::Tensor&gt; lltm_cuda_backward(
    at::Tensor grad_h,
    at::Tensor grad_cell,
    at::Tensor new_cell,
    at::Tensor input_gate,
    at::Tensor output_gate,
    at::Tensor candidate_cell,
    at::Tensor X,
    at::Tensor gate_weights,
    at::Tensor weights);
// C++ interface
#define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x " must be a CUDA tensor")
#define CHECK_CONTIGUOUS(x) AT_ASSERTM(x.is_contiguous(), #x " must be contiguous")
#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)
std::vector&lt;at::Tensor&gt; lltm_forward(
    at::Tensor input,
    at::Tensor weights,
    at::Tensor bias,
    at::Tensor old_h,
    at::Tensor old_cell) {
  CHECK_INPUT(input);
 CHECK_INPUT(weights);
  CHECK_INPUT(bias);
  CHECK_INPUT(old_h);
  CHECK_INPUT(old_cell);
  return lltm_cuda_forward(input, weights, bias, old_h, old_cell);
}
std::vector&lt;at::Tensor&gt; lltm_backward(
    at::Tensor grad_h,
    at::Tensor grad_cell,
    at::Tensor new_cell,
    at::Tensor input_gate,
    at::Tensor output_gate,
    at::Tensor candidate_cell,
    at::Tensor X,
    at::Tensor gate_weights,
    at::Tensor weights) {
  CHECK_INPUT(grad_h);
  CHECK_INPUT(grad_cell);
  CHECK_INPUT(input_gate);
  CHECK_INPUT(output_gate);
  CHECK_INPUT(candidate_cell);
  CHECK_INPUT(X);
  CHECK_INPUT(gate_weights);
  CHECK_INPUT(weights);

  return lltm_cuda_backward(
      grad_h,
      grad_cell,
      new_cell,
      input_gate,
      output_gate,
      candidate_cell,
      X,

      gate_weights,
      weights);
}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
  m.def("forward", &amp;lltm_forward, "LLTM forward (CUDA)");
  m.def("backward", &amp;lltm_backward, "LLTM backward (CUDA)");
}


</code></pre></div></div>

<p>仍然不要忘记最后让外边用的接口，这里其实就是一个如何调核函数的问题，这里面的return 后面调的就是cuda 核函数里面写的那两个函数，不过这里面并没有include 刚才写的文件，可能也是内部已经实现好了吧。</p>

<ul>
  <li>写编译文件
```
    <h1 id="setuppy">setup.py</h1>
    <p>from setuptools import setup
from torch.utils.cpp_extension import BuildExtension, CUDAExtension</p>
  </li>
</ul>

<p>setup(
    name=’lltm_cuda’,
    ext_modules=[
        CUDAExtension(‘lltm_cuda’, [
            ‘lltm_cuda.cpp’,
            ‘lltm_cuda_kernel.cu’,
        ])<br />
    ],<br />
    cmdclass={
        ‘build_ext’: BuildExtension
    })</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
运行`python setup.py install`， 和之前结果差不多，不过这时候是这样的，因为名字变了，

</code></pre></div></div>
<p>…
…
…
xtracting lltm_cuda-0.0.0-py3.6-linux-x86_64.egg to /home/pengkun/anaconda3/lib/python3.6/site-packages
lltm-cuda 0.0.0 is already the active version in easy-install.pth</p>

<p>Installed /home/pengkun/anaconda3/lib/python3.6/site-packages/lltm_cuda-0.0.0-py3.6-linux-x86_64.egg
Processing dependencies for lltm-cuda==0.0.0
Finished processing dependencies for lltm-cuda==0.0.0</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
然后可以这样用

</code></pre></div></div>
<blockquote>
  <blockquote>
    <blockquote>
      <p>import torch
import lltm_cuda
lltm_cuda.forward</p>
    </blockquote>
  </blockquote>
</blockquote>
<p>&lt;built-in method forward of PyCapsule object at 0x7f669bae2b40&gt;</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
### jit

当然这次也可以用jit的方式
</code></pre></div></div>
<blockquote>
  <blockquote>
    <blockquote>
      <p>from torch.utils.cpp_extension import load</p>

      <p>lltmCuda = load(name=’lltm_cuda’, sources=[‘lltm_cuda.cpp’, ‘lltm_cuda_kernel.cu’])
lltmCuda.forward</p>
    </blockquote>
  </blockquote>
</blockquote>
<p>&lt;built-in method forward of PyCapsule object at 0x7f63a7049f30&gt;</p>

<p>```</p>

<h3 id="后记">后记</h3>

<p>下面就准备用这种方式来重写一下之前的roc计算的。</p>


  </section>
</article>

<section>
            <div class="content-play">
              <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang" title="打赏，支持一下">多谢支持~</a></p>
              <div class="hide_box-play"></div>
              <div class="shang_box-play">
                <a class="shang_close-play" href="javascript:void(0)" onclick="dashangToggle()" title="关闭"><img src="/images/payimg/close.jpg" alt="取消" /></a>
                <div class="shang_tit-play">
                  <p>感谢您的支持，我会继续努力的!</p>
                </div>


                <!--
                <div class="shang_payimg">
                    <img src="/images/payimg/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
                </div>
                --!> 
        

                <div class="shang_payimg">
                    <img src="/images/payimg/weipayimg.jpg" alt="扫码支持" title="扫一扫" />
                </div>
            
                <div class="pay_explain">
                    扫码打赏，多谢支持~
                </div>

                <div class="shang_payselect">
        



                    <!--
                      <div class="pay_item checked" data-id="alipay">
                        <span class="pay_logo"><img src="/images/payimg/alipay.jpg" alt="支付宝" /></span>
                      </div>
                    --!> 
        
                      <!--<div class="pay_item" data-id="weipay"> --!>
                        <span class="pay_logo"><img src="/images/payimg/wechat.jpg" alt="微信" /></span>
                      <!-- </div> --!>
                </div>
            
                <div class="shang_info-play">
                  <p>打开<span id="shang_pay_txt">微信</span>扫一扫，即可进行扫码打赏哦</p>
                </div>
            
              </div>
            </div>
            <script type="text/javascript">
            function dashangToggle(){
              $(".hide_box-play").fadeToggle();
              $(".shang_box-play").fadeToggle();
            }
            </script>

            <div style="text-align:center;margin:50px 0; font:normal 14px/24px 'MicroSoft YaHei';"></div>

            <style type="text/css">
              .content-play{width:80%;margin-top: 20px;margin-bottom: 10px;height:40px;}
              .hide_box-play{z-index:999;filter:alpha(opacity=50);background:#666;opacity: 0.5;-moz-opacity: 0.5;left:0;top:0;height:99%;width:100%;position:fixed;display:none;}
              .shang_box-play{width:540px;height:540px;padding:10px;background-color:#fff;border-radius:10px;position:fixed;z-index:1000;left:50%;top:50%;margin-left:-280px;margin-top:-280px;border:1px dotted #dedede;display:none;}
              .shang_box-play img{border:none;border-width:0;}
              .dashang{display:block;width:100px;margin:5px auto;height:25px;line-height:25px;padding:10px;background-color:#E74851;color:#fff;text-align:center;text-decoration:none;border-radius:10px;font-weight:bold;font-size:16px;transition: all 0.3s;}
              .dashang:hover{opacity:0.8;padding:15px;font-size:18px;}
              .shang_close-play{float:right;display:inline-block;
                margin-right: 10px;margin-top: 20px;
              }
              .shang_logo{display:block;text-align:center;margin:20px auto;}
              .shang_tit-play{width: 100%;height: 75px;text-align: center;line-height: 66px;color: #a3a3a3;font-size: 16px;background: url('/images/payimg/cy-reward-title-bg.jpg');font-family: 'Microsoft YaHei';margin-top: 7px;margin-right:2px;}
              .shang_tit-play p{color:#a3a3a3;text-align:center;font-size:16px;}
              .shang_payimg{width:280px;padding:10px;padding-left: 140px; /*border:6px solid #EA5F00;**/margin:0 auto;border-radius:3px;height:280px;display:inline-block;}
              .shang_payimg img{display:inline-block;margin:10px auto;float:center;text-align:center;width:280px;height:280px; }
              .pay_explain{text-align:center;margin:10px auto;font-size:12px;color:#545454;}
              .shang_payselect{text-align:center;margin:5px auto;margin-top:20px;cursor:pointer;height:60px;width:500px;margin:90px auto;}
              .shang_payselect .pay_item{display:inline-block;margin:140px auto;float:center;}
              .shang_info-play{clear:both;}
              .shang_info-play p,.shang_info-play a{color:#C3C3C3;text-align:center;font-size:12px;text-decoration:none;line-height:2em;}
            </style>

       <ul class="pager">
        
        <li class="previous">
            <a href="/2018/12/clip-grid/" data-toggle="tooltip" data-placement="top" title="梯度clip">上一篇：  <span>梯度clip</span>
            </a>
        </li>
        
        
        <li class="next">
            <a href="/2018/12/anchor/" data-toggle="tooltip" data-placement="top" title="产生anchor的机制">下一篇：  <span>产生anchor的机制</span>
            </a>
        </li>
        
    </ul>
</section>

<section class="post-comments">

  

</section>


            <section class="footer">
    <footer>
        <div class = "footer_div">  
        <nav class="cover-navigation navigation--social">
          <ul class="navigation">

          

          
          <!-- Github -->
          <li class="navigation__item_social">
            <a href="https://github.com/beyondpzk" title="@beyondpzk 的 Github" target="_blank">
              <i class='social fa fa-github fa-2x'></i>
              <span class="label">Github</span>
            </a>
          </li>
          
          
          

          

          <!-- RSS -->
          <li class="navigation__item_social">
            <a href="/feed.xml" rel="author" title="RSS" target="_blank">
              <i class='social fa fa-rss fa-2x'></i>
              <span class="label">RSS</span>
            </a>
          </li>

          
          <!-- Email -->
          <li class="navigation__item_social">
            <a href="mailto:pkzhengmath@pku.edu.cn" title="Contact me">
              <i class='social fa fa-envelope fa-2x'></i>
              <span class="label">Email</span>
            </a>
          </li>
          

          </ul>
        </nav>

        </div>

        <div class = "footer_div">  
           <p class="copyright text-muted">
          <!--  Copyright &copy; 倔强的生命！ 2019 Theme by <a href="http://baixin.io/">leopardpan</a> |-->

            Copyright &copy; 倔强的生命！ 2019
            <iframe
                style="margin-left: 2px; margin-bottom:-5px;"
                frameborder="0" scrolling="0" width="91px" height="20px"
                src="https://ghbtns.com/github-btn.html?user=beyondpzk&repo=beyondpzk.github.io&type=star&count=true" >
            </iframe>
            </p>
        	<div align="right">
    			<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

          <!-- 访问统计 -->
          <span id="busuanzi_container_site_pv">
            本站总访问量
            <span id="busuanzi_value_site_pv"></span>次
          </span>

        </div>
        <div>
    </footer>
</section>

        </div>
    </div>
    
    <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>
<script type="text/javascript" src="/js/main.js"></script>

<script type="text/javascript" src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



    
  </body>

</html>
