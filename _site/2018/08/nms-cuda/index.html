<DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>CUDA-NMS</title>
  <meta name="description" content="">
  <meta name="author" content="leopardpan">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="CUDA-NMS">
  <meta name="twitter:description" content="">
  <meta property="og:type" content="article">
  <meta property="og:title" content="CUDA-NMS">
  <meta property="og:description" content="">
  
  <link rel="icon" type="image/png" href="/images/favicon.png" />
  <link href="/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="canonical" href="http://localhost:4000/2018/08/nms-cuda/">
  <link rel="alternate" type="application/rss+xml" title="倔强的生命！" href="http://localhost:4000/feed.xml">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />

<!-- 站点统计 -->
  <script 
  async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>  

<!-- 百度统计 -->
  

<!-- google 统计 -->
  

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-9005224472374751",
    enable_page_level_ads: true
  });
</script>

</head>


  <body>

    <span class="mobile btn-mobile-menu">        
      <div class="nav_container">
         <nav class="nav-menu-item" style = "float:right">
            <i class="nav-menu-item">
              <a href="/#blog" title="" class="blog-button">  博客主页
              </a>
            </i>
            
                <i class="nav-menu-item">

                  <a href="/archive" title="archive" class="btn-mobile-menu__icon">
                      所有文章
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/tags" title="tags" class="btn-mobile-menu__icon">
                      标签
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/about" title="about" class="btn-mobile-menu__icon">
                      关于我
                  </a>
                </i>
            
          </nav>
      </div>
    </span>
    
    <header class="panel-cover panel-cover--collapsed" style="background-image: url('/images/background-cover.jpg')">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">
        <!-- 头像效果-start -->
        <div class="ih-item circle effect right_to_left">            
            <a href="/#blog" title="前往 倔强的生命！ 的主页" class="blog-button">
                <div class="img"><img src="/images/avatar.jpg" alt="img"></div>
                <div class="info">
                    <div class="info-back">
                        <h2> 
                            
                                BEYOND
                            
                        </h2>
                        <p>
                           
                                Come on!
                            
                        </p>
                    </div>
                </div>
            </a>
        </div>
        <!-- 头像效果-end -->
        <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for 倔强的生命！" class="blog-button">倔强的生命！</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">何不如此！</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">欢迎~</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        
        

        <div class="navigation-wrapper">
          <div>
            <nav class="cover-navigation cover-navigation--primary">
              <ul class="navigation">
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">博客主页</a></li>
                
                  <li class="navigation__item"><a href="/archive" title="archive">所有文章</a></li>
                
                  <li class="navigation__item"><a href="/tags" title="tags">标签</a></li>
                
                  <li class="navigation__item"><a href="/about" title="about">关于我</a></li>
                
              </ul>
            </nav>
          </div>          
        </div>


        </div>
      </div>
    </div>
    
    
    <div class="panel-cover--overlay cover-clear"></div>
    
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title">CUDA-NMS</h1>
    <div class="post-meta">
      <img src="/images/calendar.png" width="20px"/> 
      <time datetime="2018-08-05 00:00:00 +0800" itemprop="datePublished" class="post-meta__date date">2018-08-05</time>  
         
      <!--<span id="busuanzi_container_page_pv"> | 阅读:<span id="busuanzi_value_page_pv"></span>次</span> -->
    </p>
    </div>
  </header>

  <section class="post">
    <!--more-->

<p>这是用cuda写nms的一个例子。</p>

<p>首先用python回忆一下nms的大致流程，</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import numpy as np

def iou(x, ys):
    # x single
    # ys mul
    lx = np.maximum(x[0], ys[:,0])
    ly = np.maximum(x[1], ys[:,1])
    rx = np.minimum(x[2], ys[:,2])
    ry = np.minimum(x[3], ys[:,3])

    I = np.maximum(0, rx-lx+1)*np.maximum(0, ry-ly+1)
    U = (x[2]-x[0]+1)*(x[3]-x[1]+1) +(ys[:,2]-ys[:,0]+1)*(ys[:,3]-ys[:,1]+1) - I
    return I*1.0/U

def nms(dets, thresh=0.5):
    # preds: score, bbox[4] (n,5)
    x = dets[:,0]
    y = dets[:,1]
    x1 = dets[:,2]
    y1 = dets[:,3]
    # areas
    areas = 1.0*(x1-x+1)*(y1-y+1)   #n

    order = dets[:,4].argsort()[::-1]
    keep = []
    while order.size &gt;0:
        i = order[0]
        keep.append(i)
        # cal IOU with others
        ious = iou(dets[i,:], dets[order[1:],:])
        passed = np.where(ious&lt;=thresh)[0]
        order = order[passed+1]
    return dets[keep,:]

</code></pre></div></div>

<p>大致过程是上面是算iou的，下面的是nms,传入的是检测框，和阈值，整个过程就是先选出分值最高的那个，
然后从里面去掉和其相交太多的。不断地重复这个过程。</p>

<h3 id="gpu的">gpu的</h3>

<p>这个是看的网上的代码，对着理解了一下，感觉写的比较高深。同时也对pytorch如何调用c++和cuda的代码有了一定的认识。实践出真知，一定要多动手。</p>

<p>现在的目录结果是这样的，</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── build.py
├── _ext
│   ├── __init__.py
│   ├── nms
│   │   ├── __init__.py
│   │   ├── _nms.so
│   │   └── __pycache__
│   │       └── __init__.cpython-35.pyc
│   └── __pycache__
│       └── __init__.cpython-35.pyc
├── __init__.py
├── nms_wrapper.py
├── pth_nms.py
├── __pycache__
│   ├── __init__.cpython-35.pyc
│   ├── nms_wrapper.cpython-35.pyc
│   └── pth_nms.cpython-35.pyc
└── src
    ├── cuda
    │   ├── nms_kernel.cu
    │   ├── nms_kernel.cu.o
    │   └── nms_kernel.h
    ├── nms.c
    ├── nms_cuda.c
    ├── nms_cuda.h
    └── nms.h

</code></pre></div></div>

<p>其中<code class="highlighter-rouge">_ext</code>这个目录是由<code class="highlighter-rouge">python build</code>来生成的。当外界调用<code class="highlighter-rouge">nms</code>的时候，用的是<code class="highlighter-rouge">from nms.nms_wrapper import nms</code>， 
其中 <code class="highlighter-rouge">nms_wrapper.py</code>这个代码我理解就是一个装饰，因为里面的内容很容易。</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    from __future__ import absolute_import
  8 from __future__ import division
  9 from __future__ import print_function
 10 
 11 from nms.pth_nms import pth_nms
 12 
 13 
 14 def nms(dets, thresh):
 15   """Dispatch to either CPU or GPU NMS implementations.
 16   Accept dets as tensor"""
 17   return pth_nms(dets, thresh)


</code></pre></div></div>

<p>所以除了cuda代码之外，最重要的就是<code class="highlighter-rouge">pth_nms.py</code>了，这个里面给了<code class="highlighter-rouge">cpu</code>和<code class="highlighter-rouge">gpu</code>两种选择。</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch
from ._ext import nms
import numpy as np

def pth_nms(dets, thresh):
  """
  dets has to be a tensor
  """
  if not dets.is_cuda:
    x1 = dets[:, 1]
    y1 = dets[:, 0]
    x2 = dets[:, 3]
    y2 = dets[:, 2]
    scores = dets[:, 4]

    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = scores.sort(0, descending=True)[1]
    # order = torch.from_numpy(np.ascontiguousarray(scores.numpy().argsort()[::-1])).long()
    keep = torch.LongTensor(dets.size(0))
    num_out = torch.LongTensor(1)
    nms.cpu_nms(keep, num_out, dets, order, areas, thresh)

    return keep[:num_out[0]]
  else:
    x1 = dets[:, 1]
    y1 = dets[:, 0]
    x2 = dets[:, 3]
    y2 = dets[:, 2]
    scores = dets[:, 4]

    dets_temp = torch.FloatTensor(dets.size()).cuda()
    dets_temp[:, 0] = dets[:, 1]
    dets_temp[:, 1] = dets[:, 0]
    dets_temp[:, 2] = dets[:, 3]
    dets_temp[:, 3] = dets[:, 2]
    dets_temp[:, 4] = dets[:, 4]
    

    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = scores.sort(0, descending=True)[1]   #得分从高到低的id。这里好像都一样了。
    dets = dets[order].contiguous()
    keep = torch.LongTensor(dets.size(0))   # 6000
    num_out = torch.LongTensor(1)  # construct a 1 Long tensor, 1 is shape,这两个都是随机的。因为在cuda核里面会改变
    nms.gpu_nms(keep, num_out, dets_temp, thresh)   # this call cuda kernel function
    return order[keep[:num_out[0]].cuda()].contiguous()   # in s


</code></pre></div></div>

<p>可见无论是用<code class="highlighter-rouge">cpu</code>还是用<code class="highlighter-rouge">gpu</code>都在_ext中写好了。其实在_ext中的是可执行文件。
原码是在<code class="highlighter-rouge">src</code>下面，里面有分别对应<code class="highlighter-rouge">cpu</code>的和对应<code class="highlighter-rouge">gpu</code>的。</p>

<p>先看看<code class="highlighter-rouge">cpu</code>的，记得当时在某云面试的时候就让我用c++来写nms，但是当时我只会用python写。</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#include &lt;TH/TH.h&gt;
#include &lt;math.h&gt;

int cpu_nms(THLongTensor * keep_out, THLongTensor * num_out, THFloatTensor * boxes, THLongTensor * order, THFloatTensor * areas, float nms_overlap_thresh) {
    // boxes has to be sorted
    THArgCheck(THLongTensor_isContiguous(keep_out), 0, "keep_out must be contiguous");
    THArgCheck(THLongTensor_isContiguous(boxes), 2, "boxes must be contiguous");
    THArgCheck(THLongTensor_isContiguous(order), 3, "order must be contiguous");
    THArgCheck(THLongTensor_isContiguous(areas), 4, "areas must be contiguous");
    // Number of ROIs
    long boxes_num = THFloatTensor_size(boxes, 0); 
    long boxes_dim = THFloatTensor_size(boxes, 1); 

    long * keep_out_flat = THLongTensor_data(keep_out);
    float * boxes_flat = THFloatTensor_data(boxes);
    long * order_flat = THLongTensor_data(order);
    float * areas_flat = THFloatTensor_data(areas);

    THByteTensor* suppressed = THByteTensor_newWithSize1d(boxes_num);
    //这个是记录每个bbox的状态的。即有没有被前面的box给过滤掉。
    THByteTensor_fill(suppressed, 0); 
    unsigned char * suppressed_flat =  THByteTensor_data(suppressed);

    // nominal indices
    int i, j;
    // sorted indices
    int _i, _j; 
    // temp variables for box i's (the box currently under consideration)
    float ix1, iy1, ix2, iy2, iarea;
    // variables for computing overlap with box j (lower scoring box)
    float xx1, yy1, xx2, yy2;
    float w, h;
    float inter, ovr;

    long num_to_keep = 0;
    for (_i=0; _i &lt; boxes_num; ++_i) {
        i = order_flat[_i];
        if (suppressed_flat[i] == 1) {  // 因为这个已经被之前的bbox给过滤掉了。所以直接pass.            continue;
        }
        //因为这个之前的许多都被过滤掉了，那这个一定是要被保存下来的。
        //比如0号bbox把1,。。。，9都pass掉了，即keep_out_flat[0] = order_flat[0]
        //keep_out_flat[1] = order_flat[10], 这样keep_out_flat最终里面存的就是要保存来的，如
果要取前100个的话，就直接可以取。
        
        keep_out_flat[num_to_keep++] = i;
        // 获得当前的这个bbox的位置信息
        ix1 = boxes_flat[i * boxes_dim];
        iy1 = boxes_flat[i * boxes_dim + 1];
        ix2 = boxes_flat[i * boxes_dim + 2];
        iy2 = boxes_flat[i * boxes_dim + 3];
        iarea = areas_flat[i];
        //从这个开始往后面去看，即算他们的IOU的大小。
        for (_j = _i + 1; _j &lt; boxes_num; ++_j) {
            j = order_flat[_j];
            if (suppressed_flat[j] == 1) {   //同样的道理，如果这个在前面已经被过滤掉了。
                continue;
            }
            xx1 = fmaxf(ix1, boxes_flat[j * boxes_dim]);
            yy1 = fmaxf(iy1, boxes_flat[j * boxes_dim + 1]);
            xx2 = fminf(ix2, boxes_flat[j * boxes_dim + 2]);
            yy2 = fminf(iy2, boxes_flat[j * boxes_dim + 3]);
            w = fmaxf(0.0, xx2 - xx1 + 1);
            h = fmaxf(0.0, yy2 - yy1 + 1);
            inter = w * h;
            ovr = inter / (iarea + areas_flat[j] - inter);
            if (ovr &gt;= nms_overlap_thresh) {  //如果IOU超过了阈值就标记为1.后面就不需要再看&gt;这个了。
                suppressed_flat[j] = 1;
            }
        }
    }

    long *num_out_flat = THLongTensor_data(num_out);
    *num_out_flat = num_to_keep;
    THByteTensor_free(suppressed);
    return 1;
}


</code></pre></div></div>

<p>综上来看，这里的logic还是非常的清晰的，即用一个suppressed_flat来标记每一个bbox的状态。来记录其是否有没有用，这种方法挺常见的。</p>

<p>然后有几个知识点不是很确定，是我自己理解的。</p>

<p><code class="highlighter-rouge">THArgCheck(THLongTensor_isContiguous(keep_out), 0, "keep_out must be contiguous");</code>这个里面的数字应该是其对应的参数的id, 即它是第0个参数。
<code class="highlighter-rouge">THByteTensor</code>这个我的理解是如果用01的话就用这个。即这个张量中的数非0即1.
<code class="highlighter-rouge">THByteTensor_fill(supressed, 0);</code>这个应该是初始化全为0.
然后用一个指针指向它
<code class="highlighter-rouge">unsigned char* suppressed_flat = THByteTensor_data(suppressed);</code></p>

<h3 id="然后来看gpu的">然后来看gpu的。</h3>

<p>gpu最重要的是要理解其内部logic，这一点是写核函数的关键。
比如开多少个block,每个block上面开多少个线程，哪些量需要是shared的，有很多的细节要处理，不然就会常 常 发生越界行为。
这里面的logic是这样的，假设现在有6000个bbox，需要通过NMS， 每个都是有5个信息的。即位置和得分。</p>

<p>那想法是开6000个线程来分别去处理每一个bbox, 但是一个block里面可能开不了那么多的线程，以我的GPU的话，每个block里面最多开1024个线程。那么通过计算，需要6个block才行。
类似于CPU写的代码，这里需要一个mask,它的shape是 （6000, 6），它的意思 是每一行代表一个bbox，其中的6指的是6个block。
比如最前面的6个，里面的数字分别代表着第0号bbox在第0,1,2,3,4,5这几个block里面过滤掉的那些框。而且它存的是从它之后的，即第10号存的就是从11号开始的。</p>

<p>torch和c连接的代码如下</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#include &lt;THC/THC.h&gt;
#include &lt;TH/TH.h&gt;
#include &lt;math.h&gt;
#include &lt;stdio.h&gt;

#include "cuda/nms_kernel.h"


extern THCState *state;

int gpu_nms(THLongTensor * keep, THLongTensor* num_out, THCudaTensor * boxes, float nms_overlap_thresh) {
  // boxes has to be sorted
  THArgCheck(THLongTensor_isContiguous(keep), 0, "boxes must be contiguous");
  THArgCheck(THCudaTensor_isContiguous(state, boxes), 2, "boxes must be contiguous");
  // Number of ROIs
  int boxes_num = THCudaTensor_size(state, boxes, 0);   //应该是6000
  printf("boxes_num: %d", boxes_num);
  int boxes_dim = THCudaTensor_size(state, boxes, 1);    //应该是5
  printf("boxes_dim : %d", boxes_dim);
  float* boxes_flat = THCudaTensor_data(state, boxes);  
  const int col_blocks = DIVUP(boxes_num, threadsPerBlock);   //6   blocks的数目。
  THCudaLongTensor * mask = THCudaLongTensor_newWithSize2d(state, boxes_num, col_blocks);   //6000×6的一个张量，但是其实还是个指针，
  unsigned long long* mask_flat = THCudaLongTensor_data(state, mask); 

//执行核函数
 _nms(boxes_num, boxes_flat, mask_flat, nms_overlap_thresh); 


</code></pre></div></div>

<p>在GPU上算完了之后，下面就是处理那个mask的过程了。</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> THLongTensor * mask_cpu = THLongTensor_newWithSize2d(boxes_num, col_blocks);
  THLongTensor_copyCuda(state, mask_cpu, mask);
  THCudaLongTensor_free(state, mask);

  unsigned long long * mask_cpu_flat = THLongTensor_data(mask_cpu);



  THLongTensor * remv_cpu = THLongTensor_newWithSize1d(col_blocks);  //假设长度是6吧，
  unsigned long long* remv_cpu_flat = THLongTensor_data(remv_cpu);
  THLongTensor_fill(remv_cpu, 0);

  long * keep_flat = THLongTensor_data(keep);
  long num_to_keep = 0;


   // 下面的过程就是处理来的那个mask的。
  int i, j;
  for (i = 0; i &lt; boxes_num; i++) {   //相当于是第几个线程来处理第几个bbox
    int nblock = i / threadsPerBlock;  //  block号
    int inblock = i % threadsPerBlock;   // 线程号。


</code></pre></div></div>

<p>上面涉及到的有从GPU到copy到CPU的函数。然后就是最关键的地方。</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   if (!(remv_cpu_flat[nblock] &amp; (1ULL &lt;&lt; inblock))) {   //按位与，只要有一个是0就是0.说明当那
个block中的还没有处理的时候，进行处理，这个是对后面的做了个清0操作。
      keep_flat[num_to_keep++] = i;   //第0号就等于i, 并且num_to_keep要加1.
      unsigned long long *p = &amp;mask_cpu_flat[0] + i * col_blocks;   // 指针指向那一行的6个数的&gt;第0个。
      for (j = nblock; j &lt; col_blocks; j++) {   // 只用当前block后面的。对呀，因为前面的可能有&gt;要它算过的了。 
        remv_cpu_flat[j] |= p[j];   //这个长度为6是一直在更新的。
      } 
    }
  }
  
  long * num_out_flat = THLongTensor_data(num_out);
  * num_out_flat = num_to_keep;

  THLongTensor_free(mask_cpu);
  THLongTensor_free(remv_cpu);


</code></pre></div></div>

<p>这一段写的感觉非常高深，首先是这个if判断这里，其中<code class="highlighter-rouge">remv_cpu_flat</code>的长度是6，是记录当前bbox的中的mask中的6个值的。刚才提到这6个mask的值分别代表着那个block中被该bbox给过滤掉的bbox的index。举个例子，比如nblock=0=inblock的时候，就假设是i=0,的时候。
第一次是能够通过if的。然后 remv_cpu_flat就会记录bbox0的mask的6个值。
假设 bbox0把bbox1,2,3,。。。，10全部都给pass掉了，其它的仍然有。
那么此时这个mask的6个值就是<code class="highlighter-rouge">[2^1+2^2+...+2^10,0,0,0,0,0]</code>,其中用二进表示的时候即
<code class="highlighter-rouge">11111111110</code>，那么只有当inblock&gt;=11的时候才会再次走if，因为<code class="highlighter-rouge">1ULL&lt;&lt;11 ---&gt;1000000000000(11个0)</code>.
其中<code class="highlighter-rouge">1ULL&lt;&lt;inblock</code>和某个数做按位与的话实际上就是把后面的位数清0。<code class="highlighter-rouge">1ULL</code>是<code class="highlighter-rouge">unsigned long long 类型的1.</code></p>

<p>感觉这个想法非常厉害。</p>

<p>本来感觉这样算了之后会不会有重复，仔细推算了一下之后，发现其实是不会的。</p>

<h3 id="核函数如何写">核函数如何写</h3>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#ifdef __cplusplus
extern "C" {
#endif

#include &lt;math.h&gt;
#include &lt;stdio.h&gt;
#include &lt;float.h&gt;
#include "nms_kernel.h"

//这个是计算IOU

__device__ inline float devIoU(float const * const a, float const * const b) {
  float left = fmaxf(a[0], b[0]), right = fminf(a[2], b[2]);
  float top = fmaxf(a[1], b[1]), bottom = fminf(a[3], b[3]);
  float width = fmaxf(right - left + 1, 0.f), height = fmaxf(bottom - top + 1, 0.f);
  float interS = width * height;
  float Sa = (a[2] - a[0] + 1) * (a[3] - a[1] + 1); 
  float Sb = (b[2] - b[0] + 1) * (b[3] - b[1] + 1); 
  return interS / (Sa + Sb - interS);
}

//核函数

__global__ void nms_kernel(const int n_boxes, const float nms_overlap_thresh,
                           const float *dev_boxes, unsigned long long *dev_mask) {
  const int row_start = blockIdx.y;
  const int col_start = blockIdx.x;//在不同的block中这些数字是不一样的。


  // if (row_start &gt; col_start) return;

  const int row_size =
        fminf(n_boxes - row_start * threadsPerBlock, threadsPerBlock);   //是每一行的线程个数吗
，还是shengxia的那些。
  const int col_size =
        fminf(n_boxes - col_start * threadsPerBlock, threadsPerBlock);

  __shared__ float block_boxes[threadsPerBlock * 5];  //这个是在一个block中的所有的线程都能够看
到的。// 1024×5

 //dev_boxes虽然是6000,5的，但是到这里面之后都当成是数组了，即6000×5的长度。
  if (threadIdx.x &lt; col_size) {
    block_boxes[threadIdx.x * 5 + 0] =
        dev_boxes[(threadsPerBlock * col_start + threadIdx.x) * 5 + 0];   //block的两个维度刚好
可以看成是pudiban,.x就是横着，.y就是竖着。
    block_boxes[threadIdx.x * 5 + 1] =
        dev_boxes[(threadsPerBlock * col_start + threadIdx.x) * 5 + 1];   //这个是在dev_boxes中
的位置。
    block_boxes[threadIdx.x * 5 + 2] =
        dev_boxes[(threadsPerBlock * col_start + threadIdx.x) * 5 + 2];
    block_boxes[threadIdx.x * 5 + 3] =
        dev_boxes[(threadsPerBlock * col_start + threadIdx.x) * 5 + 3];
    block_boxes[threadIdx.x * 5 + 4] =
        dev_boxes[(threadsPerBlock * col_start + threadIdx.x) * 5 + 4];
  }
  __syncthreads();

</code></pre></div></div>

<p>上面的操作是要把数据全部布到col上面去，然后再按行处理。</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> if (threadIdx.x &lt; row_size) {   // 一个block只能处理1024个bbox,所以这个是算当前的block的具体&gt;到某个线程时算的是哪一个bbox.
    const int cur_box_idx = threadsPerBlock * row_start + threadIdx.x;
    const float *cur_box = dev_boxes + cur_box_idx * 5;   //当前的box的第一个地址。这里的"+"相&gt;当于是移位。 //用这个指针来得到当前bbox这5个数的首地址。
    //现在就想像在某一个block里面的某个线程正在做什么？

    int i = 0;
    unsigned long long t = 0;
    int start = 0;
    if (row_start == col_start) {
      start = threadIdx.x + 1;
    }
    for (i = start; i &lt; col_size; i++) {
      if (devIoU(cur_box, block_boxes + i * 5) &gt; nms_overlap_thresh) {    //传的都是首地址， 大
于阈值的就不要了。
        t |= 1ULL &lt;&lt; i;   //t的值就变了。
      }
    }
    const int col_blocks = DIVUP(n_boxes, threadsPerBlock);   //blocks的数目 。
    dev_mask[cur_box_idx * col_blocks + col_start] = t;   //dev_mask就是记录的。   //不改就是0,改了至少是1
  }
}


//最主要的就是这个函数。
// 6000, boxes,
void _nms(int boxes_num, float * boxes_dev,
          unsigned long long * mask_dev, float nms_overlap_thresh) {

  dim3 blocks(DIVUP(boxes_num, threadsPerBlock),
              DIVUP(boxes_num, threadsPerBlock));
  dim3 threads(threadsPerBlock);
  nms_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(boxes_num,
                                  nms_overlap_thresh,
                                  boxes_dev,
                                  mask_dev);
}

#ifdef __cplusplus
}
#endif
                                                                             102,1  

</code></pre></div></div>



  </section>
</article>

<section>
            <div class="content-play">
              <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang" title="打赏，支持一下">多谢支持~</a></p>
              <div class="hide_box-play"></div>
              <div class="shang_box-play">
                <a class="shang_close-play" href="javascript:void(0)" onclick="dashangToggle()" title="关闭"><img src="/images/payimg/close.jpg" alt="取消" /></a>
                <div class="shang_tit-play">
                  <p>感谢您的支持，我会继续努力的!</p>
                </div>


                <!--
                <div class="shang_payimg">
                    <img src="/images/payimg/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
                </div>
                --!> 
        

                <div class="shang_payimg">
                    <img src="/images/payimg/weipayimg.jpg" alt="扫码支持" title="扫一扫" />
                </div>
            
                <div class="pay_explain">
                    扫码打赏，多谢支持~
                </div>

                <div class="shang_payselect">
        



                    <!--
                      <div class="pay_item checked" data-id="alipay">
                        <span class="pay_logo"><img src="/images/payimg/alipay.jpg" alt="支付宝" /></span>
                      </div>
                    --!> 
        
                      <!--<div class="pay_item" data-id="weipay"> --!>
                        <span class="pay_logo"><img src="/images/payimg/wechat.jpg" alt="微信" /></span>
                      <!-- </div> --!>
                </div>
            
                <div class="shang_info-play">
                  <p>打开<span id="shang_pay_txt">微信</span>扫一扫，即可进行扫码打赏哦</p>
                </div>
            
              </div>
            </div>
            <script type="text/javascript">
            function dashangToggle(){
              $(".hide_box-play").fadeToggle();
              $(".shang_box-play").fadeToggle();
            }
            </script>

            <div style="text-align:center;margin:50px 0; font:normal 14px/24px 'MicroSoft YaHei';"></div>

            <style type="text/css">
              .content-play{width:80%;margin-top: 20px;margin-bottom: 10px;height:40px;}
              .hide_box-play{z-index:999;filter:alpha(opacity=50);background:#666;opacity: 0.5;-moz-opacity: 0.5;left:0;top:0;height:99%;width:100%;position:fixed;display:none;}
              .shang_box-play{width:540px;height:540px;padding:10px;background-color:#fff;border-radius:10px;position:fixed;z-index:1000;left:50%;top:50%;margin-left:-280px;margin-top:-280px;border:1px dotted #dedede;display:none;}
              .shang_box-play img{border:none;border-width:0;}
              .dashang{display:block;width:100px;margin:5px auto;height:25px;line-height:25px;padding:10px;background-color:#E74851;color:#fff;text-align:center;text-decoration:none;border-radius:10px;font-weight:bold;font-size:16px;transition: all 0.3s;}
              .dashang:hover{opacity:0.8;padding:15px;font-size:18px;}
              .shang_close-play{float:right;display:inline-block;
                margin-right: 10px;margin-top: 20px;
              }
              .shang_logo{display:block;text-align:center;margin:20px auto;}
              .shang_tit-play{width: 100%;height: 75px;text-align: center;line-height: 66px;color: #a3a3a3;font-size: 16px;background: url('/images/payimg/cy-reward-title-bg.jpg');font-family: 'Microsoft YaHei';margin-top: 7px;margin-right:2px;}
              .shang_tit-play p{color:#a3a3a3;text-align:center;font-size:16px;}
              .shang_payimg{width:280px;padding:10px;padding-left: 140px; /*border:6px solid #EA5F00;**/margin:0 auto;border-radius:3px;height:280px;display:inline-block;}
              .shang_payimg img{display:inline-block;margin:10px auto;float:center;text-align:center;width:280px;height:280px; }
              .pay_explain{text-align:center;margin:10px auto;font-size:12px;color:#545454;}
              .shang_payselect{text-align:center;margin:5px auto;margin-top:20px;cursor:pointer;height:60px;width:500px;margin:90px auto;}
              .shang_payselect .pay_item{display:inline-block;margin:140px auto;float:center;}
              .shang_info-play{clear:both;}
              .shang_info-play p,.shang_info-play a{color:#C3C3C3;text-align:center;font-size:12px;text-decoration:none;line-height:2em;}
            </style>

       <ul class="pager">
        
        <li class="previous">
            <a href="/2018/08/cuda-6/" data-toggle="tooltip" data-placement="top" title="CUDA-6">上一篇：  <span>CUDA-6</span>
            </a>
        </li>
        
        
        <li class="next">
            <a href="/2018/08/cuda-7/" data-toggle="tooltip" data-placement="top" title="CUDA-7">下一篇：  <span>CUDA-7</span>
            </a>
        </li>
        
    </ul>
</section>

<section class="post-comments">

  

</section>


            <section class="footer">
    <footer>
        <div class = "footer_div">  
        <nav class="cover-navigation navigation--social">
          <ul class="navigation">

          

          
          <!-- Github -->
          <li class="navigation__item_social">
            <a href="https://github.com/beyondpzk" title="@beyondpzk 的 Github" target="_blank">
              <i class='social fa fa-github fa-2x'></i>
              <span class="label">Github</span>
            </a>
          </li>
          
          
          

          

          <!-- RSS -->
          <li class="navigation__item_social">
            <a href="/feed.xml" rel="author" title="RSS" target="_blank">
              <i class='social fa fa-rss fa-2x'></i>
              <span class="label">RSS</span>
            </a>
          </li>

          
          <!-- Email -->
          <li class="navigation__item_social">
            <a href="mailto:pkzhengmath@pku.edu.cn" title="Contact me">
              <i class='social fa fa-envelope fa-2x'></i>
              <span class="label">Email</span>
            </a>
          </li>
          

          </ul>
        </nav>

        </div>

        <div class = "footer_div">  
           <p class="copyright text-muted">
          <!--  Copyright &copy; 倔强的生命！ 2019 Theme by <a href="http://baixin.io/">leopardpan</a> |-->

            Copyright &copy; 倔强的生命！ 2019
            <iframe
                style="margin-left: 2px; margin-bottom:-5px;"
                frameborder="0" scrolling="0" width="91px" height="20px"
                src="https://ghbtns.com/github-btn.html?user=beyondpzk&repo=beyondpzk.github.io&type=star&count=true" >
            </iframe>
            </p>
        	<div align="right">
    			<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

          <!-- 访问统计 -->
          <span id="busuanzi_container_site_pv">
            本站总访问量
            <span id="busuanzi_value_site_pv"></span>次
          </span>

        </div>
        <div>
    </footer>
</section>

        </div>
    </div>
    
    <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>
<script type="text/javascript" src="/js/main.js"></script>

<script type="text/javascript" src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



    
  </body>

</html>
