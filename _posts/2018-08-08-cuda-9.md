---
layout: post
title: CUDA-9
date: 2018-08-09
categories: [CUDA]
tags: CUDA
---
<!--more-->

这次要学习一下常量内存，主要是因为在某些情况下常量内存替换全局内存能够有效的减少内存带宽。
常量内存用于保存在核函数执行期间不会发生变化的数据，使用常量内存能降低GPU运算单元的空闲等待。

为什么使用常量内存能够提升性能，原因如下：

* 对常量内存的单次操作可以广播到其他的邻近线程，会节约15次读取的操作。

* 高速缓存，常量内存的数据将缓存起来，因此对于相同地址的连续操作将不会产生额外的内存通信量。

在cuda的架构中，一个线程束有32个线程，它们被编织在一起，并且是步调一致地在执行。
当处理常量内存的时候，NVIDIA硬件将把单次内存读取操作广播到半线程束中，即16个线程，所以少了15次操作。最终这种方式产生的内存流量只是使用全局内存时的`1/16`。

常量内存用`__constant__`来声明，使用`cudaMemcpyToSymbol`把数据从主机copy到设备GPU中。比如书上的光线racing的例子，因为随机产生的20个球在整个核函数运行过程中都是不变的，所以应该声明为常量内存，减少内存通信量。

所以以后在写类似的任务时，就可以把这一类的量声明为常量内存。
