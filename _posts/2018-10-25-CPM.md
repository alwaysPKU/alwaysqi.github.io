---
layout: post
title: CPM 论文笔记
date: 2018-10-25 11：55 +0800
categories: [论文笔记]
tags: 论文笔记
---
<!--more-->

paper全名是《Convolutional Pose Machines》是CMU(Carnegie Mellon University)的一篇paper.

###  大致想法
用层级形式的CNN来预测一个置信图，这个置信图中表示的是人的part在这个位置上的概率。
网络结构图如图
![avatar](/images/cpm1.png)

### 输入
刚开始的输入是图片，往后的每一层的stage，输入的都是前一个stage的输出，和每一个层都shared的X，X是由最初的输入经过一些层而得到的。关于这一点，paper里特别作出了说明，

![avatar](/images/cpm3.png)
![avatar](/images/cpm2.png)

意思是这里从stage2之后用到的和第一层的可能不太一样，而之前pose machine里面是一样的，
这里确实值得注意一下，我理解相当于是在进入每一层之前先加一些层让网络适应一下进入下一层。
### 输出
网络分为多个stage，每一层的输出都是置信图，代表着关键点在那个位置上的概率。

### gt
现在意识到gt是个很重要的东西，以前以为标注的东西就是gt呢，现在才意识到其实不是的，gt要和网络结合起来来做，而且不同的网络架构对于gt的要求也不一样。
这里的gt采用的是在关键点附近做一个高斯分布，那么在关键点的地方，这个值就是1，离他越远，就越小，可能在实际中会有一个阈值来卡一个距离，超过这个距离之后，即认为离关键点太远了，那么就让其为0.所以gt的制作只用到了原图的keypoints的信息，图片的语义信息没有用到。
### 大致过程
输入，输出，gt有了之后，那么整体的流程是这样的。
前期是提特征，然后进入stage1,注意进入stage1的和从stage1出来的shape是一样的，不同的是channel数不同，gt的heatmap也和这个shape是一样的。
网络会学习图片的特征，然后预测一个置信图，这个置信图取值为[0,1]，然后gt的heatmap的取值也是[0,1]，然后这两个pointwise 地作一个l2的norm，就是这个stage1的loss,其余层的也是如此。这样就可以end-to-end的训练下去。
### inference
inference阶段也非常重要，可能在单人的时候并不太明显，因为单人的时候，只要关键点检测出来了，那么各个part直接连接起来就可以了。
但是在多人的时候这个问题就会变得复杂，如果采用先检测关键点的方式的话，那么当关键点检测完了之后，如何把关键点连接起来是个比较困难的问题。
然后单人检测的时候，我理解测试的时候只要取对应channel上的最大的值，应该就可以了，这样每个channel上预测一个点。个人理解。
在看openpose的时候发现在测试的时候不是这样子的，测试的时候每一个Part会检测出多个点，因为这可能是不同的人的手的位置.所以每一个part上可能会预测出好几个点。
所以openpose的测试代码是非常值得学习的。

我之前看代码时，当看到每一个part上可能会有多个点时，我当时以为可能是怕精度不高，所以多保留几个，然后再做筛选，现在才意识到其实是因为一张图上可能有多个人，那么就可能有多个不同的关键点但是标注的是同一个part.
### Q
现在非常想了解的是，如果想做到精确检测，该如何来做。猜测这方面应该和人脸的landmark有比较大的联系，因为那里面如果错了，整个人就错了。下一步准备查一下相关的论文。

