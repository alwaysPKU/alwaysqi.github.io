---
layout: post
title: DSSD 论文笔记
date: 2018-09-13 11：55 +0800
categories: [论文笔记]
tags: 论文笔记
---
<!--more-->

###  关键词

论文链接: [https://arxiv.org/abs/1701.06659](https://arxiv.org/abs/1701.06659)

初步印象：
Deconvolution  + SSD---->DSSD

上图：

![avatar](/images/dssd1.png)

可以看到是在SSD的基础之上添加了deconv层，不过这里的base 网络是resnet-101,不再是之前的vgg了，因为resnet101效果比较好。

### Motivation
SSD虽然在速度上非常快，在精度上也还不错，但是想要提高精度以及对于小物体的检测的话，还有许多的提升空间。
回顾SSD网络，虽然它用了multi-scale的feature map，但是各个feature map 并没有很好的结合起来做检测，而且后面的几个feature map 都是从前面的得来的。

而实际上感受野比较大的适合检测大物体，可以想像用望远镜看远方的话，大楼比较明显，所以较深层的网络适合做这件事情，感受野较小的比较适合检测小物体，所以想像如果两个结合起来的话，即把浅层的信息和深层的信息结合起来效果会不会更好一些呢，实践证明确实好了很多。

感觉有点像FPN中的top--down结构，不过文中说这里用的是可学习的deconvolution,而不是直接用的bilinear 插值upsampling。

见下图：
![avator](/images/dssd2.png)

与fpn的：
![avator](/images/dssd3.png)

嗯，是挺相似的，如果把DSSD的顺转90度看的话。

### predict layer
关于预测层，也有好几种，上图：
![avator](/images/dssd4.png)

(a)就是原始的ssd中的，文中说把上面的4种都试了，最终选择的c，
关于预测模块作者也说，不能弄的太负杂了，否则会影响速度，

### Deconvolutional layer
再上一个比较细致的图：
![avator](/images/dssd5.png)
能够看出一路是deconv,一路是比较常见的cnn--bn--relu block。
然后逐个相乘，这一点和在其他地方见到的不太一样，
这里作者说做了相乘和相加的实验，发现相乘的时候结果更好一些。

这个从理论上该如何解释？
其实以前见FPN里面用加的时候，当时也想过其他操作，
比如可以concat，或者加权相加，因为不同深度的层的权重未必一样，可以用一个可学习的加权参数来让网络自己调整。相乘的话，有点像逐个的加了权（或scale）的感觉。

从这里也可以看出，这里面的运算还是不少的，肯定会降低原来SSD的速度。不光是做了deconv，还要把之前的做了处理之后，再相乘。
### priori bbox
文章中是这么说的：

![avator](/images/dssd6.png)

相比之前做了改动，也采用yolo2的里面的k-means聚类的想法来决定anchor bbox的个数。然后关于ratio，作者也发现大部分的bbox都在1--3之间，所以在原来的基础上添加了又一个1.6。








