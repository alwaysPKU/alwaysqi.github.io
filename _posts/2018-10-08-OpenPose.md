---
layout: post
title: OpenPose 论文笔记
date: 2018-10-08 11：55 +0800
categories: [论文笔记]
tags: 论文笔记
---
<!--more-->

###  文章大致思路
PAFS,即part affinity fields.意思是人体关节之间的一个关系图。这篇文章的大意是网络有两支，其中一支预测人体的关键点，其中的一支预测PAFS，有了PAFS之后可以建立关键点之间的关系，这样就形成了一个图模型。然后再用图论中的匈牙利算法来给关键点匹配。

### 背景介绍
人体关键点检测是个非常有挑战性的一个cv的方向，因为自然场景中有许多不确定的因素，比如人数不确定，人与人之间会有重叠，各种姿势，人的高矮，胖瘦等等。
目前的方法主要有两种，一种是top-down的方法，即先把人给检测出来，然后再对每个人来估计它的动作和关键点，这种方法有以下缺点，
-如果人检测不出来，那后面的就无法谈起，所以对于人检测器的精度要求比较高
-计算量会随着场景中的人数的上升而增加，
另外一种方式是先不管有多少个人，先把关键点给检测出来，然后再用图模型的办法进行关键点和具体的人的匹配操作，即要做的是哪个关键点属于哪个人的，哪些关键点是同一个人的。
这个paper里面用的是后者的方法，文中说叫bottom-up的方法，这个bottom-up 也和paper中设计的网络的形状有些关系。bottom-up的方法也有缺点，paper中说是 do not directly use global contextual cues from other body parts and other people.
网络结构如图所示：
![avatar](/images/openpose1.png)
前面是提特征，然后分为上下两个支路，其中上支路预测confidence maps S 下支路预测affinity fields L，然后不断地进行迭代，每一层的输入都有两部分，一部是F即原feature，一部分是前一层的输出，
见公式

![avatar](/images/openpose2.png)

回过来解释下S和L是什么，
见paper

![avatar](/images/openpose3.png)
即S有J个channel，每个channel负责一个part，每一个channel的（w,h）就是输入的图片的size（w,h），
比如对于第j个part，在Sj里面肯定有最大值的地方，那么这个像素点就认为是第j个part的位置。（应该是这样的）。
然后L有C个channel，每个都是一个向量场，代表人体的一个limb,其shape为(w,h,2)即每个位置上预测的是一个“方向”，所以是向量场.(我理解limb和part的区别是一个limb上可能有多个part，比如胳膊上可能有好多个关键点需要预测。)

### loss-function
见图

![avatar](/images/openpose4.png)
因为考虑到数据集上可能并不是对所有人都打了label，所以用一个mask W（p）来作为区分，如果annotation无效的话w(p)就为0，否则就为1。
-不太理解其中的"the mask is used to avoid penalizing the TP predictions during traing."
-中间层的监督学习过程中可能会有梯度消失的问题，这里说定期的增加梯度，31是他们之前的CPM。
-或许最终的损失函数加上权值会好一些，可以让权值也通过学习来得到

gt是这么定义的，

![avatar](/images/openpose5.png)
![avatar](/images/openpose6.png)

其中x[j,k]代表第k个人的第j个part的位置，那么其对应的gt S^[j,k]在位置p的gt值为上面的那个式子，
那么因为同一个位置可能会有多个人的关键点在此重合，比如握手，勾肩搭背，所以最终在位置p的gt
用(7)来定义，即在所有的人里面取最大值，并且还给了一个图来解释为什么要取最大而不取平均。
从图中也可以看出来，两个高斯峰点不相同的时候，相当于两个关键点离得不太近，那么这时候两个值都应该是大的，是能够明显区别的。
L的gt下面讲。
### PAF
这个paper里面的最重要的东西可能就是它了。这个的motivation是当检测出一些body parts之后，那么接下来的问题就是如何把这些body parts给连起来来形成整个人体的姿态，那么这时候问题就来了，
-不知道有多个人
-需要一个东西来衡量任两个已检测到的body parts之间的关联强度

可能的解决方案有
-用一个额外的中间点
但是这样不太好，因为当人挤到一块儿的时候，容易把不是同一个人的关键点给联系起来，比如两个人握手时，那么这两个人的手的关键点离的肯定比他们各自的手离肩膀的近。

paper 里面给出的是这个例子。其中黄的是中间点，绿的就是错的，黑的才是正确的。
![avatar](/images/openpose7.png)

作者分析了原因之后，觉得应该同时预测出关键点了之后，还要把每个limb的方向给预测出来，
这样即使不同的人的part离的很近但是方向并不对，那他们也无法联系到一块儿，个人觉得这个想法挺赞的
。这样就催生了PAF。

![avatar](/images/openpose8.png)

下面解释gt的L是怎么回事儿。
x[j1,k],x[j2,k]是第k个人的第c个limb 中的body part（可理解为是关键点附近的一片位置）j1和body part j2，
如果p在limb上的话就取值为由x[j1,k]指向x[j2,k]的单位向量，否则的话就为0，判断p是否在limb c上的方法是看其在是否在由v和v^张成的一个小矩形内，其长度为x[j1,k]与x[j2,k]之间的距离，而宽度是一个像素点数（不太确定我有没有翻译对）。
然后gt的L在p处的值是在每个人上的平均。

### testing 阶段
前面的训练过程有了检测的parts 和 PAFS之后，那么就可以建立parts之间的关系，
公式如图

![avatar](/images/openpose9.png)
即两点之间的一个线积分。可能叫第一型曲线积分，不太记得了。
### Multi-Person Parsing using PAFS
paper 中是这么说的

![avatar](/images/openpose10.png)
即现在有了许多的parts，要决定哪些应该连在一起，d[m,j1]代表第j1个part的第m个候选，Nj表示第j个part的候选的数量。
用Z[m,n][j1,j2]来表示第j1个part的第m个候选和第j2个part的第n个候选是否相连，如果是1就是相连，0就是不连，

图的节点是D[j1]={D[j1,m] | m 可取1,2,,,.N[j1]}，也就是节点是一个候选的集合。
而边是D[j1]到D[j2]的所有可能的连接，并且每个边有权值E，即上面的那个积分定义。
感觉这一块儿不是太理解，先上几个公式

![avatar](/images/openpose11.png)

![avatar](/images/openpose12.png)
