---
layout: post
title: 有哪些原因可能导致网络不收敛
date: 2018-10-02
categories: [DL]
tags: DL
---
<!--more-->

有时候非常难受的事情是网络不收敛，这时候要思考其原因在哪里，找不到原因的话，训练一个月都有可能。特别是对于一些大项目，因为不能够在刚开始的时候就看出其不收敛了，而是在训练了一周了才发现不收敛，这样就很伤心了，所以一定要注意这个问题。在网上找了一些可能的原因会导致网络发散，作一下记录。

### 没有对数据归一化

#### 为什么归一化？
这个其实挺自然的，因为数据中特征的量纲不一，所以需要作标准化处理。
而且许多的神经网络从权值初始化到激活函数，还有优化算法，都假设了输入输出是在0附近的分布。

操作是去均值除标准差。

### 没有对数据前期处理
这个前期处理是非常的重要的，特别是数据有没有效，如果gt都是错的话，这种情况很严重。最终的结果肯定也不会怎么好，因为本来就是错的。

有的可能要把数据过滤一下才可以用。

### 没有正则化

正则化也非常重要，是防止过拟合的好办法。

### 学习率的设置有问题

如果其他地方没有发现问题的话，那这个很有可能是原因。这个其实可能得动手试一下，才能找到合适的。
### 没有正确初始化权值
这个就像Banach不动点定理的证明里展示的一样，初始化的选择将决定迭代多少步能够达到想要的精度。有些可以0初始化，但是如果最好的模型与初始化的时候不太一致的时候，网络可能要花很长时间才能适应，甚至都适应不了，也就是不收敛了。这个可能要根据经验对于最终的模型有个predict，然后试着做合适的初始化。

所以从上面来看，有些东西虽然不可捉摸的感觉，但是多做多积累经验，并且掌握一定的理论基础，一定会有所帮助的。






